{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"IMPORTING ALL THE NECCESSARY MODULES"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport nltk\nimport re\nfrom nltk.corpus import stopwords\nfrom nltk.stem.wordnet import WordNetLemmatizer\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom nltk.tokenize import word_tokenize\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nnltk.download('punkt')\nnltk.download('stopwords')\nnltk.download('wordnet')\nfrom textblob import TextBlob","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Reading the datasets of the four companies Oneplus,Apple,Vivo and Samsung on which we will perform EDA to see the problems the companies are facing ."},{"metadata":{"trusted":true},"cell_type":"code","source":"Oneplus =pd.read_csv(\"/kaggle/input/oneplusnordreviews/Oneplus.csv\")\nIphone=pd.read_csv(\"/kaggle/input/iphonereviews/Iphone.csv\")\nSamsung=pd.read_csv(\"/kaggle/input/samsungreviews/Samsung.csv\")\nVivo=pd.read_csv('/kaggle/input/vivoreview/Vivo.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Adding Company column to all the DataFrames before we merge into main DataFrame."},{"metadata":{"trusted":true},"cell_type":"code","source":"Iphone['Company']='Apple'\nIphone","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Oneplus['Company']='Oneplus'\nOneplus","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Samsung['Company']='Samsung'\nSamsung","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Vivo['Company']='Vivo'\nVivo","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, we will create a main DataFrame called 'result' to merge all the datasets into it."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Create a empty DataFrame \nresult=pd.DataFrame()\ns=[Vivo,Iphone,Samsung,Oneplus]\n#Append all the other companies review data into Result DataFrame.\nfor i in s:\n    result=result.append(i);\nresult.reset_index(inplace=True)\nresult","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Using TextBlob we will Sentiment of the following reviews and based on that score we will classify sentiment into 'Positive', 'Negative' and 'Neutral'. Before using Textblob we will clean the review to get more accurate sentiment score."},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_sentiment_textblob(message):\n    clean_message=' '.join(re.sub('\\n', \" \", message).split())\n    analysis=TextBlob(clean_message)\n    score=analysis.sentiment.polarity \n    if score > 0:\n        return \"Positive\"\n    else: \n        return \"Negative\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, we will create a seperate column of Sentiment which we will get from the above defined function when we process our review to get Setniment using TextBlob library."},{"metadata":{"trusted":true},"cell_type":"code","source":"get_sentiment_textblob(result['Comment'][0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result['Sentiment_Textblob_Comment']=result['Comment'].apply(get_sentiment_textblob)\nresult['Sentiment_Textblob_Title']=result['Title'].apply(get_sentiment_textblob)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **DATA PREPROCESSING**"},{"metadata":{},"cell_type":"markdown","source":"We will define a function for Preprocessing our review.Preprocessing pipeline includes:\n1. Lower casing the text.\n2. Tokenize into words.\n3. Filtering out words by removing punctuations,'@','/n'etc.\n4. Removing Stopwords.\n5. Lemmatization."},{"metadata":{"trusted":true},"cell_type":"code","source":"#def preprocess(message):\n #   message=message.lower()\n  #  token=word_tokenize(message)\n    \n    #remove some negation words from stopwords list\n   # rem_sw=[\"no\",\"not\"]\n    #stop_words=set([word for word in stopwords.words('english') if word not in rem_sw])\n    #clean_review=[word for word in text if word not in stop_words]\n    #clean_review_text=[word for word in clean_review if len(word)>=2]\n    #lemmatizer=WordNetLemmatizer()\n    #final_review=[lemmatizer.lemmatize(word) for word in clean_review_text]\n    #final=' '.join(final_review)\n    #return final\nimport string\npunc = set(string.punctuation)\n\ndef preprocess(text):\n    # Convert the text into lowercase\n    text = text.lower()\n    # Split into list\n    wordList=text.split()\n    #print(wordList)\n    #wordList = word_tokenize(text)\n    # Remove punctuation\n    wordList = [\"\".join(x for x in word if (x==\"'\")|(x not in punc)) for word in wordList]\n    wordList=[t for t in wordList if re.match(r'^[a-z]',t)]\n    # Remove stopwords\n    wordList = [word for word in wordList if word not in stopwords.words('english')]\n    wordList=[word for word in wordList if len(word)>=2]\n    # Lemmatisation\n    lemmatizer=WordNetLemmatizer()\n    wordList = [lemmatizer.lemmatize(word) for word in wordList]\n    return \" \".join(wordList)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result['Comment']=[preprocess(sent) for sent in result['Comment']]\nresult['Title']=[preprocess(sent) for sent in result['Title']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Coverting the Rating string into integer for predict Sentiment from Ratings.\nresult['Rating']=[int(t[0]) for t in result.Rating]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will define a function to get Sentiment of user by the Ratings he gave for the product. The Sentiment Classification according to the ratings are as follows:\n1. 'Negative' Sentiment for Ratings in range [1,2].\n2. 'Neutral' Sentiment for Ratings equal to 3.\n3. 'Positive' Sentiment for Ratings in range [4,5]."},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_sentiment(x):\n    if(x<=2):\n        return \"Negative\"\n    else:\n        return \"Positive\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Convert Rating string into integer.\nresult['Sentiment_Rating']=result['Rating'].apply(get_sentiment)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Percentage of Sentiment using Textblob and Sentiment using Rating do not match\ncount=result[result['Sentiment_Textblob_Comment']!=result['Sentiment_Rating']]\nprint(count.shape,result.shape)\nprint((count.shape[0]/result.shape[0])*100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Visualisation"},{"metadata":{},"cell_type":"markdown","source":"**Plotting Average rating per Brand**"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n# Average rating per brand\nax = result.groupby(\"Company\").mean()[\"Rating\"].sort_values().plot(kind=\"barh\",\n                                                                figsize=(8,5), \n                                                                title=\"Average rating per Brand\")\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Visualising Count of Sentiment according to Ratings of Different Companies**"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(18,8))\nsns.countplot(x = 'Company', hue = 'Sentiment_Rating', data = result)\nplt.xlabel('Moods', fontsize = 18)\nplt.ylabel('Count', fontsize = 18)\nplt.title('Count of Moods', fontsize = 24)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Segregating the result DataFrame into Comapny wise DataFrame."},{"metadata":{"trusted":true},"cell_type":"code","source":"Op=result[result['Company']=='Oneplus']\nIp=result[result['Company']=='Apple']\nVivo=result[result['Company']=='Vivo']\nSamsung=result[result['Company']=='Samsung']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Joining all Positive and Negative reviews for counting Bigrams frequencies. "},{"metadata":{"trusted":true},"cell_type":"code","source":"Op_pos=' '.join(Op[(Op['Sentiment_Rating']=='Positive')]['Comment'])\nIp_pos=' '.join(Ip[(Ip['Sentiment_Rating']=='Positive')]['Comment'])\nIp_neg=' '.join(Ip[(Ip['Sentiment_Rating']=='Negative')]['Comment'])\nOp_neg=' '.join(Op[(Op['Sentiment_Rating']=='Negative')]['Comment'])\nVivo_pos=' '.join(Vivo[(Vivo['Sentiment_Rating']=='Positive')]['Comment'])\nSam_pos=' '.join(Samsung[(Samsung['Sentiment_Rating']=='Positive')]['Comment'])\nVivo_neg=' '.join(Vivo[(Vivo['Sentiment_Rating']=='Negative')]['Comment'])\nSam_neg=' '.join(Samsung[(Samsung['Sentiment_Rating']=='Negative')]['Comment'])\nresult_pos=' '.join(result[result['Sentiment_Rating']=='Positive']['Comment'])\nresult_neg=' '.join(result[result['Sentiment_Rating']=='Negative']['Comment'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**WORDCLOUD of Bigrams using Bigram_Frequency**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#  Create Bigram_frequency Dictionary.\nfrom wordcloud import WordCloud, ImageColorGenerator\ndef word_freq_dict(text):\n    # Convert text into word list\n    stopwords=['amazon','oneplus','iphone','apple','vivo','samsung','plus','nord','phone','mobile','good']\n    wordList=text.split()\n    wordList=[word for word in wordList if word not in stopwords]\n    bigram=nltk.bigrams(wordList)\n    fdist = nltk.FreqDist(bigram)\n    # Generate bigram freq dictionary\n    wordFreqDict={k[0]+' '+k[1]:v for k,v in fdist.items()}\n    return wordFreqDict\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def wordcloud_from_frequency(word_freq_dict, title, figure_size=(10, 6)):\n    wordcloud.generate_from_frequencies(word_freq_dict)\n    plt.figure(figsize=figure_size)\n    plt.imshow(wordcloud)\n    plt.axis(\"off\")\n    plt.title(title)\n    plt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define a function to plot top15 positive words and top15 negative words in a grouped bar plot (from dictionaries)\ndef topn_wordfreq_bar_both(pos_word_freq_dict, neg_word_freq_dict, pos_num_doc, neg_num_doc, topn, title1, title2,palette1,palette2,Org,height=10):\n    # Transform positive word frequency into DF\n    df_pos = pd.DataFrame.from_dict(pos_word_freq_dict, orient=\"index\").sort_values(by=0, ascending=False).head(topn)\n    df_pos.columns = [\"frequency\"]\n    df_pos[\"frequency\"] = df_pos[\"frequency\"] / pos_num_doc\n    df_pos[\"label\"] = \"Positive\"\n    df_pos['Company']=Org\n    df_pos.reset_index(inplace=True)\n    # Transform negative word frequency into DF\n    df_neg = pd.DataFrame.from_dict(neg_word_freq_dict, orient=\"index\").sort_values(by=0, ascending=False).head(topn)\n    df_neg.columns = [\"frequency\"]\n    df_neg[\"frequency\"] = df_neg[\"frequency\"] / neg_num_doc\n    df_neg[\"label\"] = \"Negative\"\n    df_neg['Company']=Org\n    df_neg.reset_index(inplace=True)\n    # Plot\n    print(df_pos)\n    sns.catplot(x=\"index\", y=\"frequency\", hue=\"label\", data=df_pos, \n                kind=\"bar\",\n                palette=palette1,\n                height=height,aspect=2,\n                legend_out=True)\n    plt.title(title1+Org)\n    plt.show()\n    print(df_neg)\n    sns.catplot(x=\"index\", y=\"frequency\", hue=\"label\", data=df_neg, \n                kind=\"bar\",\n                palette=palette2,\n                height=height,aspect=2,\n                legend_out=True)\n    plt.title(title2+Org)\n    plt.show()\n    return df_pos,df_neg","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot wordclouds for latest 1000 reviews for Apple\nIp_pos_word_freq = word_freq_dict(Ip_pos)\nwordcloud = WordCloud(width=5000, \n                      height=3000, \n                      max_words=200, \n                      colormap=\"Blues\",\n                      background_color=\"white\")\nwordcloud_from_frequency(Ip_pos_word_freq, \"Most Frequent Words in the Latest 1000 Positive Reviews for Apple\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot wordclouds for latest 1000 negativereviews for Apple\nIp_neg_word_freq = word_freq_dict(Ip_neg)\nwordcloud = WordCloud(width=5000, \n                      height=3000, \n                      max_words=200, \n                      colormap=\"Blues\",\n                      background_color=\"Black\")\nwordcloud_from_frequency(Ip_neg_word_freq, \"Most Frequent Words in the Latest 1000 Negative Reviews for Apple\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plotting top 15 positive and negative words for Apple\nApple_top_pos,Apple_top_neg=topn_wordfreq_bar_both(Ip_pos_word_freq, Ip_neg_word_freq, \n                       min(sum(Ip['Sentiment_Rating']=='Positive'), 1000), \n                       min(sum(Ip['Sentiment_Rating']=='Negative'), 1000), \n                       15, \n                       \"Top15 Frequent Words in Latest Positive for\",\"Top15 Frequent Words in Latest Negative for\",[\"lightblue\"],[\"lightcoral\"],   \n                       \"Apple\",height=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot wordclouds for latest 1000 positive reviews for Oneplus\nOp_pos_word_freq = word_freq_dict(Op_pos)\nwordcloud = WordCloud(width=5000, \n                      height=3000, \n                      max_words=200, \n                      colormap=\"Blues\",\n                      background_color=\"white\")\nwordcloud_from_frequency(Op_pos_word_freq, \"Most Frequent Words in the Latest 1000 Positive Reviews for Oneplus\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot wordclouds for latest 1000 negativereviews for Oneplus\nOp_neg_word_freq = word_freq_dict(Op_neg)\nwordcloud = WordCloud(width=5000, \n                      height=3000, \n                      max_words=200, \n                      colormap=\"Blues\",\n                      background_color=\"Black\")\nwordcloud_from_frequency(Op_neg_word_freq, \"Most Frequent Words in the Latest 1000 Negative Reviews for Oneplus\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plotting top 15 positive and negative words for Oneplus\nOp_top_pos,Op_top_neg=topn_wordfreq_bar_both(Op_pos_word_freq, Op_neg_word_freq, \n                       min(sum(Op['Sentiment_Rating']=='Positive'), 1000), \n                       min(sum(Op['Sentiment_Rating']=='Negative'), 1000), \n                       15, \n                       \"Top15 Frequent Words in Latest Positive for\",\"Top15 Frequent Words in Latest Negative for\",[\"lightblue\"],[\"lightcoral\"], \n                       \"Oneplus\",height=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot wordclouds for latest 1000 positive reviews for Vivo\nVivo_pos_word_freq = word_freq_dict(Vivo_pos)\nwordcloud = WordCloud(width=5000, \n                      height=3000, \n                      max_words=200, \n                      colormap=\"Blues\",\n                      background_color=\"white\")\nwordcloud_from_frequency(Vivo_pos_word_freq, \"Most Frequent Words in the Latest 1000 Positive Reviews for Vivo\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot wordclouds for latest 1000 negativereviews for Vivo\nVivo_neg_word_freq = word_freq_dict(Vivo_neg)\nwordcloud = WordCloud(width=5000, \n                      height=3000, \n                      max_words=200, \n                      colormap=\"Blues\",\n                      background_color=\"Black\")\nwordcloud_from_frequency(Vivo_neg_word_freq, \"Most Frequent Words in the Latest 1000 Negative Reviews for Vivo\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plotting top 15 positive and negative words for Vivo\nVivo_top_pos,Vivo_top_neg=topn_wordfreq_bar_both(Vivo_pos_word_freq, Vivo_neg_word_freq, \n                       min(sum(Vivo['Sentiment_Rating']=='Positive'), 1000), \n                       min(sum(Vivo['Sentiment_Rating']=='Negative'), 1000), \n                       15, \n                       \"Top15 Frequent Words in Latest Positive for\",\"Top15 Frequent Words in Latest Negative for\",[\"lightblue\"],[\"lightcoral\"],\n                       \"Vivo\",height=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot wordclouds for latest 1000 positive reviews for Samsung\nSam_pos_word_freq = word_freq_dict(Sam_pos)\nwordcloud = WordCloud(width=5000, \n                      height=3000, \n                      max_words=200, \n                      colormap=\"Blues\",\n                      background_color=\"white\")\nwordcloud_from_frequency(Sam_pos_word_freq, \"Most Frequent Words in the Latest 1000 Positive Reviews for Samsung\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot wordclouds for latest 1000 negativereviews for Samsung\nSam_neg_word_freq = word_freq_dict(Sam_neg)\nwordcloud = WordCloud(width=5000, \n                      height=3000, \n                      max_words=200, \n                      colormap=\"Blues\",\n                      background_color=\"Black\")\nwordcloud_from_frequency(Sam_neg_word_freq, \"Most Frequent Words in the Latest 1000 Negative Reviews for Samsung\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plotting top 15 positive and negative words for Samsung\nSam_top_pos,Sam_top_neg=topn_wordfreq_bar_both(Sam_pos_word_freq, Sam_neg_word_freq, \n                       min(sum(Samsung['Sentiment_Rating']=='Positive'), 1000), \n                       min(sum(Samsung['Sentiment_Rating']=='Negative'), 1000), \n                       15, \n                       \"Top15 Frequent Words in Latest Positive for\",\"Top15 Frequent Words in Latest Negative for\",[\"lightblue\"],[\"lightcoral\"],\n                       \"Samsung\",height=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#finding common bigrams in top15 Positive and Negative reviews of All Companies.\ncommon_values_neg = set.intersection(set(Op_top_neg['index']), set(Apple_top_neg['index']), set(Vivo_top_neg['index']), set(Sam_top_neg['index']))\ncommon_values_pos=set.intersection(set(Op_top_pos['index']), set(Apple_top_pos['index']), set(Vivo_top_pos['index']), set(Sam_top_pos['index']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"common_values_neg","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"common_values_pos","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Common_bigrams_neg = pd.concat([Op_top_neg[Op_top_neg['index'].isin(common_values_neg)], Apple_top_neg[Apple_top_neg['index'].isin(common_values_neg)], Vivo_top_neg[Vivo_top_neg['index'].isin(common_values_neg)],Sam_top_neg[Sam_top_neg['index'].isin(common_values_neg)]], ignore_index=True)\nCommon_bigrams_pos = pd.concat([Op_top_pos[Op_top_pos['index'].isin(common_values_pos)], Apple_top_pos[Apple_top_pos['index'].isin(common_values_pos)], Vivo_top_pos[Vivo_top_pos['index'].isin(common_values_pos)],Sam_top_pos[Sam_top_pos['index'].isin(common_values_pos)]], ignore_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Common_bigrams_neg.sort_values(\"frequency\" ,axis = 0, ascending = False, \n                 inplace = True, na_position ='last')\nCommon_bigrams_neg","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Common_bigrams_pos.sort_values([\"index\",\"frequency\"] ,axis = 0, ascending = False, \n                 inplace = True, na_position ='last')\nCommon_bigrams_pos","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Common Negative Features \n # Draw a nested barplot of common negative features of different companies.\nax = sns.barplot(x=\"Company\", y=\"frequency\", hue=\"index\", data=Common_bigrams_neg)\nplt.title(\"Frequency of common Negative features of different companies\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Common Negative Features \n # Draw a nested barplot of common positive features of different companies.\nax = sns.barplot(x=\"Company\", y=\"frequency\", hue=\"index\", data=Common_bigrams_pos)\nplt.title(\"Frequency of common Positive features of different companies\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# SENTIMENT ANALYSIS USING Naive Bayes"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Covert Sentiment into Binary Classification of format('-1': Negative,'1' :Positive)\nsent_dict = {'Positive':1, 'Negative':-1}\nfor key, value in sent_dict.items():\n    result['Sentiment_Rating'] = result['Sentiment_Rating'].replace(key, value)\nresult","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Create Bag of Words Model \nX=result['Comment']\ny=result['Sentiment_Rating']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\nvectorizer=CountVectorizer()\nBOW=vectorizer.fit_transform(X_train)\ndf=pd.DataFrame(BOW.toarray(),columns=vectorizer.get_feature_names())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"count=result['Sentiment_Rating'].value_counts()\nprint(count)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\n\nsm = SMOTE()\n\nX_train_res, y_train_res = sm.fit_sample(BOW, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"unique, counts = np.unique(y_train_res, return_counts=True)\nprint(list(zip(unique, counts)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\n\nnb = MultinomialNB()\n\nnb.fit(X_train_res, y_train_res)\n\nnb.score(X_train_res, y_train_res)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test_vect = vectorizer.transform(X_test)\n\ny_pred = nb.predict(X_test_vect)\n\ny_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n\nprint(\"Accuracy: {:.2f}%\".format(accuracy_score(y_test, y_pred) * 100))\nprint(\"\\nF1 Score: {:.2f}\".format(f1_score(y_test, y_pred) * 100))\nprint(\"\\nCOnfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}